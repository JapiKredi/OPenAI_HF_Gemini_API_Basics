{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK04vrxWpj7hIczHWY8NSG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JapiKredi/OPenAI_HF_Gemini_API_Basics/blob/main/OPenAI_HF_Gemini_API_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import OPENAI Key"
      ],
      "metadata": {
        "id": "qql5gCO5tP6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5fCyxt5hs2AG"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('openai_key')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Gemini Key"
      ],
      "metadata": {
        "id": "7nqD9RHntUPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "_jgJSjtvtWMx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import HuggingFace API Key"
      ],
      "metadata": {
        "id": "MYx6XVFftWvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HUGGINGFACE_API_KEY = userdata.get('HuggingFace_API_KEY')"
      ],
      "metadata": {
        "id": "Sd9zsIbvtZRx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"google/gemma-7b\""
      ],
      "metadata": {
        "id": "rKCwKoWlvj61"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "w7C7Kq_ezolF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#API_URL=\"https://api-inference.huggingface.co/models/google/gemma-7b\"\n",
        "API_URL=\"https://api-inference.huggingface.co/models/google/gemma-7b\""
      ],
      "metadata": {
        "id": "z9HfiUN0zpU1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_API_KEY}\"}"
      ],
      "metadata": {
        "id": "Ha6JRR4U0SOg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query(payload):\n",
        "  response=requests.post(API_URL,headers=headers,json=payload)\n",
        "  print(response)\n",
        "  return response.json()"
      ],
      "metadata": {
        "id": "MSFNZE7E1bTQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question={\n",
        "\t\"inputs\": \"can you let me about the capital of india\",\n",
        "}"
      ],
      "metadata": {
        "id": "VNAYa-P64z-2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = query(question)"
      ],
      "metadata": {
        "id": "KGCk7xMG1ya_",
        "outputId": "ed85afad-4fc8-4f57-f7f4-a27ca0397bfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "ppusG1_k12vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e97f40a-6c24-4cea-aecb-b595a436c8fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'can you let me about the capital of india\\n\\nAnswer:\\nThe capital of India is New Delhi.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "176lR9MG3f8x",
        "outputId": "c247cbd4-75b6-4365-be8c-8acb51516dae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'generated_text': 'can you let me about the capital of india\\n\\nAnswer:\\nThe capital of India is New Delhi.'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn7VvduI4pcN",
        "outputId": "e2656ccb-4784-42ff-e264-b8aa6cdedfde"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can you let me about the capital of india\n",
            "\n",
            "Answer:\n",
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POdBd_qt4tCS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mistral model"
      ],
      "metadata": {
        "id": "baPmxkJ34-iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL=\"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-v0.1\""
      ],
      "metadata": {
        "id": "jdk56HMW4_7w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query(payload):\n",
        "  response=requests.post(API_URL,headers=headers,json=payload)\n",
        "  print(response)\n",
        "  return response.json()"
      ],
      "metadata": {
        "id": "VwbjNceg5cOo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question={\n",
        "\t\"inputs\": \"can you let me about the capital of india\",\n",
        "}"
      ],
      "metadata": {
        "id": "2Cnc9rrB5fD1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = query(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PbG4xOg5g69",
        "outputId": "2784cd43-6e03-4598-d21d-b1655b733fad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [503]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p5hwWlk5ix1",
        "outputId": "ee4e5fce-d7b5-4729-8a60-3e51c27e66ca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'error': 'Model mistralai/Mistral-7B-v0.1 is currently loading',\n",
              " 'estimated_time': 579.3385620117188}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Falcon model"
      ],
      "metadata": {
        "id": "TBhgDmQl51r0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "API_URL=\"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
        "#API_URL=\"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-gemma-v0.1\"\n",
        "#https://huggingface.co/HuggingFaceH4/zephyr-7b-beta"
      ],
      "metadata": {
        "id": "qPW1D3AQ5nZ4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query(payload):\n",
        "  response=requests.post(API_URL,headers=headers,json=payload)\n",
        "  print(response)\n",
        "  return response.json()"
      ],
      "metadata": {
        "id": "Do19UUkr6cTm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question={\n",
        "\t\"inputs\": \"can you let me about the capital of india\",\n",
        "}"
      ],
      "metadata": {
        "id": "-lFL1c3S6vbU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = query(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaG1q1g36xJn",
        "outputId": "2db61c53-a4a5-437b-c43f-b9910d2c197b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtkIRugU6y9J",
        "outputId": "f9ed1e32-52b9-4989-a310-4805c21df70a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"can you let me about the capital of india?\\nI know New Delhi is the Capital of India; it's governance is in the hands of Lieutenant Governor, appointed by President of India and the federal government is elected under the provisions of Indian Constitution. It lies near the confluence of river Yamuna(East) and river Chambal (West). The union territories encircling New Delhi are Chhattarpur, Gurgaon, Faridabad, Karnal, Alwar and R\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPENAI"
      ],
      "metadata": {
        "id": "L63kcxIn8RdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('openai_key')"
      ],
      "metadata": {
        "id": "prISzApf60oi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/guides/text-generation"
      ],
      "metadata": {
        "id": "KGO0x0M48TPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuwQtynv9Q4m",
        "outputId": "b233ed7d-0d33-4832-b293-0a7715e69880"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m163.8/227.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "p997gTg19YXy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "phb_Disj9vM_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.models.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki4jA24u_G5D",
        "outputId": "bb6fabed-c20b-48d8-83bd-5735b5356dd7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncPage[Model](data=[Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system')], object='list')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = client.models.list().data"
      ],
      "metadata": {
        "id": "1XYGkj25_TFV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "idDIfSGe_ay2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(models,columns=['ids','creation_date', 'x','y'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sb2-Dt9t_dyd",
        "outputId": "11656f2f-6d06-409d-f947-46f72cc159aa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  ids          creation_date                x  \\\n",
              "0          (id, gpt-4-vision-preview)  (created, 1698894917)  (object, model)   \n",
              "1                      (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
              "2        (id, text-embedding-3-large)  (created, 1705953180)  (object, model)   \n",
              "3           (id, gpt-4-turbo-preview)  (created, 1706037777)  (object, model)   \n",
              "4            (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
              "5                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
              "6   (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
              "7                     (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
              "8                 (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
              "9                      (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
              "10                  (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
              "11       (id, text-embedding-3-small)  (created, 1705948997)  (object, model)   \n",
              "12       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
              "13                        (id, tts-1)  (created, 1681940951)  (object, model)   \n",
              "14           (id, gpt-3.5-turbo-0125)  (created, 1706048358)  (object, model)   \n",
              "15                (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
              "16                  (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
              "17           (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
              "18                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
              "19       (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
              "20           (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
              "21            (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
              "22                        (id, gpt-4)  (created, 1687882411)  (object, model)   \n",
              "23                   (id, gpt-4-0613)  (created, 1686588896)  (object, model)   \n",
              "24       (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
              "25           (id, gpt-4-1106-preview)  (created, 1698957206)  (object, model)   \n",
              "26           (id, gpt-4-0125-preview)  (created, 1706037612)  (object, model)   \n",
              "\n",
              "                              y  \n",
              "0            (owned_by, system)  \n",
              "1            (owned_by, system)  \n",
              "2            (owned_by, system)  \n",
              "3            (owned_by, system)  \n",
              "4            (owned_by, openai)  \n",
              "5            (owned_by, system)  \n",
              "6            (owned_by, system)  \n",
              "7   (owned_by, openai-internal)  \n",
              "8            (owned_by, system)  \n",
              "9            (owned_by, system)  \n",
              "10           (owned_by, system)  \n",
              "11           (owned_by, system)  \n",
              "12           (owned_by, system)  \n",
              "13  (owned_by, openai-internal)  \n",
              "14           (owned_by, system)  \n",
              "15           (owned_by, openai)  \n",
              "16           (owned_by, system)  \n",
              "17           (owned_by, openai)  \n",
              "18           (owned_by, system)  \n",
              "19  (owned_by, openai-internal)  \n",
              "20           (owned_by, system)  \n",
              "21  (owned_by, openai-internal)  \n",
              "22           (owned_by, openai)  \n",
              "23           (owned_by, openai)  \n",
              "24           (owned_by, openai)  \n",
              "25           (owned_by, system)  \n",
              "26           (owned_by, system)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-752ce7e1-a682-4971-8b3d-c7350a31a768\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ids</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(id, gpt-4-vision-preview)</td>\n",
              "      <td>(created, 1698894917)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(id, dall-e-3)</td>\n",
              "      <td>(created, 1698785189)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(id, text-embedding-3-large)</td>\n",
              "      <td>(created, 1705953180)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(id, gpt-4-turbo-preview)</td>\n",
              "      <td>(created, 1706037777)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
              "      <td>(created, 1686587434)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(id, dall-e-2)</td>\n",
              "      <td>(created, 1698798177)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
              "      <td>(created, 1694122472)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(id, whisper-1)</td>\n",
              "      <td>(created, 1677532384)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(id, tts-1-hd-1106)</td>\n",
              "      <td>(created, 1699053533)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(id, tts-1-hd)</td>\n",
              "      <td>(created, 1699046015)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(id, babbage-002)</td>\n",
              "      <td>(created, 1692634615)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(id, text-embedding-3-small)</td>\n",
              "      <td>(created, 1705948997)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
              "      <td>(created, 1692901427)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(id, tts-1)</td>\n",
              "      <td>(created, 1681940951)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
              "      <td>(created, 1706048358)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(id, gpt-3.5-turbo)</td>\n",
              "      <td>(created, 1677610602)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(id, davinci-002)</td>\n",
              "      <td>(created, 1692634301)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
              "      <td>(created, 1677649963)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(id, tts-1-1106)</td>\n",
              "      <td>(created, 1699053241)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>(id, text-embedding-ada-002)</td>\n",
              "      <td>(created, 1671217299)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
              "      <td>(created, 1698959748)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
              "      <td>(created, 1683758102)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>(id, gpt-4)</td>\n",
              "      <td>(created, 1687882411)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>(id, gpt-4-0613)</td>\n",
              "      <td>(created, 1686588896)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
              "      <td>(created, 1685474247)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>(id, gpt-4-1106-preview)</td>\n",
              "      <td>(created, 1698957206)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>(id, gpt-4-0125-preview)</td>\n",
              "      <td>(created, 1706037612)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-752ce7e1-a682-4971-8b3d-c7350a31a768')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-752ce7e1-a682-4971-8b3d-c7350a31a768 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-752ce7e1-a682-4971-8b3d-c7350a31a768');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cbd3847b-28b4-4c8a-9fc5-6f96c872fecc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cbd3847b-28b4-4c8a-9fc5-6f96c872fecc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cbd3847b-28b4-4c8a-9fc5-6f96c872fecc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"ids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          [\n            \"id\",\n            \"tts-1-hd-1106\"\n          ],\n          [\n            \"id\",\n            \"tts-1\"\n          ],\n          [\n            \"id\",\n            \"tts-1-hd\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"creation_date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          [\n            \"created\",\n            1699053533\n          ],\n          [\n            \"created\",\n            1681940951\n          ],\n          [\n            \"created\",\n            1699046015\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          [\n            \"object\",\n            \"model\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          [\n            \"owned_by\",\n            \"system\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "DXczui0o8tVq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCJBb3b69OfG",
        "outputId": "bf2cfb47-b7b9-44f1-bdce-7f5bf2e8fca2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-8yEScWr0mSWwQLQZ5gqEw6o5dJ7JE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The 2020 World Series was played at Globe Life Field in Arlington, Texas.', role='assistant', function_call=None, tool_calls=None))], created=1709365958, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_2b778c6b35', usage=CompletionUsage(completion_tokens=17, prompt_tokens=53, total_tokens=70))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuoCzoSH-Y_3",
        "outputId": "88b308b8-b91a-4aae-bfc7-3c62b732941a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The 2020 World Series was played at Globe Life Field in Arlington, Texas.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are the most funniest assistant who describes everything in the funniest way\"},\n",
        "    {\"role\": \"user\", \"content\": \"Create a poem for the Indian people\"},\n",
        "    #{\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "    #{\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "_1wv4ofy-gMu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbnw-daWB2dl",
        "outputId": "443cf98c-213e-42a8-a1ae-a7a216deec0e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-8yEShn7dTo8S63mOuQvtaGvxICZE1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, lovely people of India, so diverse and bold,\\nWith colors and spices, your stories are told.\\nFrom the bustling streets of Mumbai to the Taj Mahal,\\nYour spirit and resilience, we can all hail.\\n\\nIn sarees and turbans, you dance and you sing,\\nCelebrating life with every little thing.\\nThe rhythm of your hearts echoes through the land,\\nUniting in joy, hand in hand.\\n\\nFrom the Himalayas to the beaches of Goa,\\nYour beauty and culture, a delightful show.\\nWith laughter and chai, you welcome all,\\nIn your warmth and kindness, we stand tall.\\n\\nSo here's to you, India, a nation so great,\\nWith a history and future that's bound to fascinate.\\nMay your laughter never fade, your spirit forever shine,\\nOh, Indian people, you are simply divine!\", role='assistant', function_call=None, tool_calls=None))], created=1709365963, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_2b778c6b35', usage=CompletionUsage(completion_tokens=168, prompt_tokens=33, total_tokens=201))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMrlgM9wB9qb",
        "outputId": "204251f8-5a84-48fc-f971-b23691150237"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, lovely people of India, so diverse and bold,\\nWith colors and spices, your stories are told.\\nFrom the bustling streets of Mumbai to the Taj Mahal,\\nYour spirit and resilience, we can all hail.\\n\\nIn sarees and turbans, you dance and you sing,\\nCelebrating life with every little thing.\\nThe rhythm of your hearts echoes through the land,\\nUniting in joy, hand in hand.\\n\\nFrom the Himalayas to the beaches of Goa,\\nYour beauty and culture, a delightful show.\\nWith laughter and chai, you welcome all,\\nIn your warmth and kindness, we stand tall.\\n\\nSo here's to you, India, a nation so great,\\nWith a history and future that's bound to fascinate.\\nMay your laughter never fade, your spirit forever shine,\\nOh, Indian people, you are simply divine!\", role='assistant', function_call=None, tool_calls=None))]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJKFJeLzB_wC",
        "outputId": "1c551b29-f66f-4897-eb54-800e0f94e77b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, lovely people of India, so diverse and bold,\\nWith colors and spices, your stories are told.\\nFrom the bustling streets of Mumbai to the Taj Mahal,\\nYour spirit and resilience, we can all hail.\\n\\nIn sarees and turbans, you dance and you sing,\\nCelebrating life with every little thing.\\nThe rhythm of your hearts echoes through the land,\\nUniting in joy, hand in hand.\\n\\nFrom the Himalayas to the beaches of Goa,\\nYour beauty and culture, a delightful show.\\nWith laughter and chai, you welcome all,\\nIn your warmth and kindness, we stand tall.\\n\\nSo here's to you, India, a nation so great,\\nWith a history and future that's bound to fascinate.\\nMay your laughter never fade, your spirit forever shine,\\nOh, Indian people, you are simply divine!\", role='assistant', function_call=None, tool_calls=None))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ouOoGgsCD3Y",
        "outputId": "8467fc9e-3366-4608-f7b3-6cd7aa5efb9b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content=\"Oh, lovely people of India, so diverse and bold,\\nWith colors and spices, your stories are told.\\nFrom the bustling streets of Mumbai to the Taj Mahal,\\nYour spirit and resilience, we can all hail.\\n\\nIn sarees and turbans, you dance and you sing,\\nCelebrating life with every little thing.\\nThe rhythm of your hearts echoes through the land,\\nUniting in joy, hand in hand.\\n\\nFrom the Himalayas to the beaches of Goa,\\nYour beauty and culture, a delightful show.\\nWith laughter and chai, you welcome all,\\nIn your warmth and kindness, we stand tall.\\n\\nSo here's to you, India, a nation so great,\\nWith a history and future that's bound to fascinate.\\nMay your laughter never fade, your spirit forever shine,\\nOh, Indian people, you are simply divine!\", role='assistant', function_call=None, tool_calls=None)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMageGeneration"
      ],
      "metadata": {
        "id": "QzyIGxSvCfvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"a white siamese cat\",\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "\n",
        "image_url = response.data[0].url"
      ],
      "metadata": {
        "id": "Mbsbhr9PCF8K"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "hWd2ML8YCnnB",
        "outputId": "e2fd2e8d-3d1e-4a59-b7eb-6511d5a5e39b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-saZrRAbIVP2awMHvtI1LJlAq/user-Cub0eIsDW4qEpe49jAP2Y0tc/img-ibijHC6SfMvIFiD7EUpiyER5.png?st=2024-03-02T06%3A53%3A12Z&se=2024-03-02T08%3A53%3A12Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-02T06%3A08%3A21Z&ske=2024-03-03T06%3A08%3A21Z&sks=b&skv=2021-08-06&sig=Gt5Ukm09QbvhltXgSjJ1A7ljXOCgmn6HlL%2BwPyhnT3A%3D'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gemini Model"
      ],
      "metadata": {
        "id": "-SVkfzL7E-Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "0Zpu3N-mCxrD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "OG6fYgj2E_8B"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "bMIc-KR-FH2s"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for models in genai.list_models():\n",
        "  print(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wruwTzb-FO6J",
        "outputId": "53fad38c-fae1-43b8-e120-f42fb9af34a5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/chat-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 Chat (Legacy)',\n",
            "      description='A legacy text-only model optimized for chat conversations',\n",
            "      input_token_limit=4096,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
            "      temperature=0.25,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/text-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 (Legacy)',\n",
            "      description='A legacy model that understands text and generates text as an output',\n",
            "      input_token_limit=8196,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
            "      temperature=0.7,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/embedding-gecko-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding Gecko',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=1024,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=1)\n",
            "Model(name='models/gemini-1.0-pro-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
            "                   'model that supports tuning.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=1)\n",
            "Model(name='models/gemini-1.0-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Latest',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
            "                   'model.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=1)\n",
            "Model(name='models/gemini-1.0-pro-vision-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/gemini-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=1)\n",
            "Model(name='models/gemini-pro-vision',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/embedding-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding 001',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=2048,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedContent'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/aqa',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Model that performs Attributed Question Answering.',\n",
            "      description=('Model trained to return answers to questions that are grounded in provided '\n",
            "                   'sources, along with estimating answerable probability.'),\n",
            "      input_token_limit=7168,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateAnswer'],\n",
            "      temperature=0.2,\n",
            "      top_p=1.0,\n",
            "      top_k=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for models in genai.list_models():\n",
        "  if \"generateContent\" in models.supported_generation_methods:\n",
        "    print(models.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "NIP4uvlPFthj",
        "outputId": "5ae18097-692e-4a93-bef1-be6b9a4ac06a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_text=genai.GenerativeModel(\"gemini-1.0-pro\")"
      ],
      "metadata": {
        "id": "I5A9x5CwF27X"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_text.generate_content(\"what is a capital of india and give me a sweet pe on capital of india\")"
      ],
      "metadata": {
        "id": "1BWlvqCIGEy4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2b6ab16c-33ea-4e52-968a-4b5200878d98"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.generativeai.types.generation_types.GenerateContentResponse at 0x7852682752a0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_text.generate_content(\"what is a capital of india and give me a sweet pe on capital of india\")"
      ],
      "metadata": {
        "id": "wUVSmfISG0kp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6ctZB-SG5yk",
        "outputId": "c6c64f41-de05-440d-9afb-6647ef08bac1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.generativeai.types.generation_types.GenerateContentResponse at 0x785268275450>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "_Ed_HfY-G-2n",
        "outputId": "b1aa79f1-ed4a-4181-f900-15a8a0cb8c62"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"**Capital of India:** New Delhi\\n\\n**Sweet Poem on the Capital of India:**\\n\\nIn the heart of India, a city grand,\\nNew Delhi, a capital planned.\\nWith towering spires and wide boulevards,\\nA symbol of progress, it proudly stands.\\n\\nRajpath unfurls like a regal road,\\nWhere processions grace with vibrant load.\\nIndia Gate, a majestic sight,\\nReminds us of heroes who fought with might.\\n\\nAkshardham Temple, a serene abode,\\nWhere faith and beauty sweetly reside.\\nLotus Temple, a floral dream,\\nA sanctuary of peace, a tranquil gleam.\\n\\nConnaught Place, a bustling hub,\\nWhere shoppers roam and deals are done.\\nChandni Chowk, a labyrinthine street,\\nA foodie's paradise, a delightful treat.\\n\\nNew Delhi, a city full of life,\\nWhere history blends with modern strife.\\nA vibrant tapestry, rich and bold,\\nA capital worthy, stories untold.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUb51ukkHAf5",
        "outputId": "04876d0d-7341-495d-ad17-5367fdccc8d0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[content {\n",
              "  parts {\n",
              "    text: \"**Capital of India:** New Delhi\\n\\n**Sweet Poem on the Capital of India:**\\n\\nIn the heart of India, a city grand,\\nNew Delhi, a capital planned.\\nWith towering spires and wide boulevards,\\nA symbol of progress, it proudly stands.\\n\\nRajpath unfurls like a regal road,\\nWhere processions grace with vibrant load.\\nIndia Gate, a majestic sight,\\nReminds us of heroes who fought with might.\\n\\nAkshardham Temple, a serene abode,\\nWhere faith and beauty sweetly reside.\\nLotus Temple, a floral dream,\\nA sanctuary of peace, a tranquil gleam.\\n\\nConnaught Place, a bustling hub,\\nWhere shoppers roam and deals are done.\\nChandni Chowk, a labyrinthine street,\\nA foodie\\'s paradise, a delightful treat.\\n\\nNew Delhi, a city full of life,\\nWhere history blends with modern strife.\\nA vibrant tapestry, rich and bold,\\nA capital worthy, stories untold.\"\n",
              "  }\n",
              "  role: \"model\"\n",
              "}\n",
              "finish_reason: STOP\n",
              "index: 0\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.parts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FQuIZwLHCtV",
        "outputId": "53bacf19-fd85-4f08-80e4-afb913b9dbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[text: \"**Capital of India:** New Delhi\\n\\n**Sweet P\\303\\251on (Poem) on New Delhi**\\n\\nIn the heart of India\\'s vast embrace,\\nLies New Delhi, a vibrant space.\\nWith ancient ruins whispering tales untold,\\nAnd modern marvels, a sight to behold.\\n\\nRed Fort stands tall, a fortress of might,\\nWitness to history\\'s tumultuous flight.\\nIndia Gate, a symbol of pride,\\nHonoring those who for freedom died.\\n\\nParliament House, where leaders convene,\\nShaping India\\'s destiny, making it serene.\\nQutub Minar, a tower so grand,\\nA testament to the skills of a master\\'s hand.\\n\\nConnaught Place, bustling with life,\\nWhere shoppers roam and vendors strive.\\nTemples and mosques, a symphony of faith,\\nEchoing the diversity our nation embraceth.\\n\\nNew Delhi, a city of dreams and aspirations,\\nWhere the past and future find harmonious relations.\\nA vibrant mosaic, a cultural tapestry,\\nA capital of pride, an Indian legacy.\"\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini image models"
      ],
      "metadata": {
        "id": "vvsAU8ajHNtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_image=genai.GenerativeModel(\"gemini-1.0-pro-vision-latest\")"
      ],
      "metadata": {
        "id": "Bh0pKr7JHFOS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o image.jpg \"https://www.hindustantimes.com/ht-img/img/2023/03/24/550x309/robert-lukeman-zNN6ubHmruI-unsplash_1679659189331_1679659234951_1679659234951.jpg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3CXyCJbHFSR",
        "outputId": "423f671c-23ac-4be2-8648-0990ec8071f5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 58659    0 58659    0     0   202k      0 --:--:-- --:--:-- --:--:--  202k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image"
      ],
      "metadata": {
        "id": "l77Wt28GHUrb"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=PIL.Image.open(\"image.jpg\")"
      ],
      "metadata": {
        "id": "MXHvlFRoHXbP"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_image.generate_content(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "3-KR5ab9IV2i",
        "outputId": "bc780a67-9767-4596-d43f-1f50bb74d74b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.generativeai.types.generation_types.GenerateContentResponse at 0x78526afff5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AiAVDHwII48Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}